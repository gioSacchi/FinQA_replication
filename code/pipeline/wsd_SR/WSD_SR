import pandas as pd
import random
import nltk
from nltk import word_tokenize, pos_tag
from nltk.stem import WordNetLemmatizer
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
# nltk.download('tagsets')
nltk.download('universal_tagset')   
lemmatizer = WordNetLemmatizer()


def preprocess_text(row):
    # takes in row and return dictionary with topkenized text, pos tags, lemmas and selected indecies
    augmeneted = {}
    qa = row['qa']




def main():
  input_path = r"E:\FinQA_replication\dataset\train.json"
  df = pd.read_json(input_path)

  print(len(df))

  # number of generated sentences per original sentence
  num_aug = 5
  random.seed(3)
  ## Remove retriever columns
  df = df.drop(['table_retrieved','text_retrieved','table_retrieved_all','text_retrieved_all', 'table_ori', 'filename'], axis=1)
  # random_ind = random.sample(range(len(df)), 3)
  for df_index, row in df.iterrows():
  # for df_index in random_ind:
    # row = df.iloc[df_index]
    # Dropping unneeded columns, remove program_re???
    row['qa'] = {"question": row['qa']["question"], "program": row['qa']["program"], "gold_inds": row['qa']["gold_inds"], "exe_ans": row['qa']["exe_ans"], "program_re": row['qa']["program_re"]}
    if df_index % 100 == 0:
      print(df_index)
    for n in range(num_aug):
        new_row = WSD_synonym_replacement(row, df_index)
        if new_row:
          new_row['id'] = new_row['id'] + "_SR_PoS_num_aug_" + str(df_index) + "_" + str(n)
          df = pd.DataFrame.append(df, new_row, ignore_index=True)

  print(len(df))
  output_path = r"E:\FinQA_replication\dataset\train_SR_PoS_augmented.json"
  df.to_json(output_path, orient='records', indent=4)


"""problem in general is that it is hard to get correct form of word. eg changes 
    gives synset change which has lemma alter which will replace changes. But correct 
    would be plural form of alter alterations. How does one do that? Put in to a 
    grammar check. Necessary? Maybe adds noise which is good anyways"""

if __name__ == '__main__':
  main()